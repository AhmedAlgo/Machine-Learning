{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical Data Preparation steps\n",
    "\n",
    " - Getting the necessary python libraries \n",
    " - Loading the dataset \n",
    " - Dealing with **Missing values** & **Categorical features** \n",
    " - Splitting the data into **Training sets** & **Testing sets**\n",
    " - Normalization of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importin Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now import some required libraries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           City   Age    Salary Approved\n",
      "0  Apple Valley  25.0   65000.0      Yes\n",
      "1     Maplewood  30.0   81000.0       No\n",
      "2         Eagan  33.0       NaN      Yes\n",
      "3  Apple Valley  39.0  100000.0       No\n",
      "4     Maplewood  28.0   91000.0      Yes\n",
      "5         Eagan   NaN   66000.0       No\n",
      "6  Apple Valley  40.0   98000.0      Yes\n",
      "7     Maplewood  34.0   86000.0      Yes\n",
      "8         Eagan  25.0   70000.0       No\n",
      "9     Maplewood  24.0   62000.0      Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eagan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple Valley</td>\n",
       "      <td>40.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maplewood</td>\n",
       "      <td>34.0</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eagan</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maplewood</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           City   Age   Salary Approved\n",
       "5         Eagan   NaN  66000.0       No\n",
       "6  Apple Valley  40.0  98000.0      Yes\n",
       "7     Maplewood  34.0  86000.0      Yes\n",
       "8         Eagan  25.0  70000.0       No\n",
       "9     Maplewood  24.0  62000.0      Yes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset \n",
    "\n",
    "dataset = pd.read_csv('loans.csv') #Store the dataset in a dataframe\n",
    "print(dataset)\n",
    "\n",
    "dataset.head() #Show the begining of the file\n",
    "dataset.tail() #Show the begining of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Apple Valley' 25.0 65000.0]\n",
      " ['Maplewood' 30.0 81000.0]\n",
      " ['Eagan' 33.0 nan]\n",
      " ['Apple Valley' 39.0 100000.0]\n",
      " ['Maplewood' 28.0 91000.0]\n",
      " ['Eagan' nan 66000.0]\n",
      " ['Apple Valley' 40.0 98000.0]\n",
      " ['Maplewood' 34.0 86000.0]\n",
      " ['Eagan' 25.0 70000.0]\n",
      " ['Maplewood' 24.0 62000.0]]\n",
      "\n",
      "['Yes' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:,:-1].values   # [:, :-1] Store all the raws, Store all the columns except the last one\n",
    "\n",
    "y = dataset.iloc[:,3].values    # [:,3] Store all the raws,  Store colum 3 (Approved)\n",
    "\n",
    "print (X)\n",
    "print ()\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "Rows with missing values can be easily dropped via the dropna method >>> df.dropna(axis=0)\n",
    "\n",
    "Similarly, we can drop columns that have at least one NaN in any row by setting the axis argument to 1 >>> df.dropna(axis=1)\n",
    "\n",
    "Only drop rows where all columns are NaN >>> df.dropna(how='allâ€™)\n",
    "\n",
    "Keep only the rows with at least 2 non-NaN values. >>> df.dropna(thresh=2)\n",
    "\n",
    "Only drop rows where NaN appear in specific columns (here: 'C') >>> df.dropna(subset=['C'])\n",
    "\n",
    "Note: df is the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50000000e+01 6.50000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.00000000e+01 8.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 3.30000000e+01 7.98888889e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.90000000e+01 1.00000000e+05]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 2.80000000e+01 9.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 3.08888889e+01 6.60000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.00000000e+01 9.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.40000000e+01 8.60000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 2.50000000e+01 7.00000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 2.40000000e+01 6.20000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Dealing with missing values \n",
    "\n",
    "# From the scikit.impute library we first import the SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Next we define an object of the SimpleImputer class by looking at the docstring (use Shift+Tab)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "imputer.fit(X[:,[1,2]])\n",
    "\n",
    "X[:,1:3]= imputer.transform(X[:,1:3])\n",
    "\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 2.50000000e+01 6.50000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 3.00000000e+01 8.10000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 3.30000000e+01 7.98888889e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.90000000e+01 1.00000000e+05]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 2.80000000e+01 9.10000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 3.08888889e+01 6.60000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.00000000e+01 9.80000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 3.40000000e+01 8.60000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00 2.50000000e+01 7.00000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00 2.40000000e+01 6.20000000e+04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Dealing with categorical variables\n",
    "\n",
    "#From the scikit.preprocessing library we first import few classes\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "\n",
    "labelencoder_X = LabelEncoder() \n",
    "\n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0]) \n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0]) \n",
    "\n",
    "X = onehotencoder.fit_transform(X).toarray() \n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Dealing with categorical variables\n",
    "##From the scikit.preprocessing library we first import few classes\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "\n",
    "labelencoder_X = LabelEncoder() \n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0]) \n",
    "onehotencoder = OneHotEncoder(categorical_features=[0]) \n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#Dependent variable \n",
    "labelencoder_y = LabelEncoder() \n",
    "y = labelencoder_y.fit_transform(y)\n",
    "\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "\n",
    "- Training Set \n",
    "- Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into Training Set and Test Set\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2) #Test size = 20%, training size = 80% \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    " - MinMax Approach\n",
    " - Mean Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler() \n",
    "\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
