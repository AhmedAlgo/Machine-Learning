{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "- ## All features\n",
    "- ## Backward Elimination\n",
    "- ## Forward Selection\n",
    "- ## Hybrid of Backward and Forward (also called Stepwise)\n",
    "- ## All combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "- Getting the necessary python libraries\n",
    "- Loading the dataset\n",
    "- Dealing with Missing values & Categorical features\n",
    "- Splitting the data into Training sets & Testing sets\n",
    "- Normalization of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Getting the necessary python libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "#Loading the dataset\n",
    "dataset = pd.read_csv('employee.csv') #Store the dataset in a dataframe\n",
    "#print(dataset)\n",
    "\n",
    "# [:, :-1] Store all the raws, Store all the columns except the last one\n",
    "X = dataset.iloc[:,:-1].values   \n",
    "# [:,3] Store all the raws,  Store colum 3\n",
    "y = dataset.iloc[:,4].values    \n",
    "\n",
    "#Dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "labelencoder_X = LabelEncoder() \n",
    "X[:,0] = labelencoder_X.fit_transform(X[:,0]) \n",
    "onehotencoder = OneHotEncoder(categorical_features=[0]) \n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Removing the extra dummy vareiable\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Test size = 20%, training size = 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>WorkedHours</th>\n",
       "      <th>Certification</th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Development</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Testing</td>\n",
       "      <td>2100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>46205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Development</td>\n",
       "      <td>2104</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1254</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1236</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>56642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Development</td>\n",
       "      <td>1452</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>54445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1645</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>64445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1258</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>57189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1478</td>\n",
       "      <td>3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>63218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Development</td>\n",
       "      <td>1257</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Development</td>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1256</td>\n",
       "      <td>2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>57081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1489</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>61111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Development</td>\n",
       "      <td>1236</td>\n",
       "      <td>3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>67938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Testing</td>\n",
       "      <td>2311</td>\n",
       "      <td>2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>66029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>2245</td>\n",
       "      <td>3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>83088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Development</td>\n",
       "      <td>2365</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>81363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Development</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1456</td>\n",
       "      <td>2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>91738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>98273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>2400</td>\n",
       "      <td>4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>101302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Development</td>\n",
       "      <td>2148</td>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1450</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>109431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>105582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1540</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>116969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Development</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>112635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Testing</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>10.3</td>\n",
       "      <td>122391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UX Designer</td>\n",
       "      <td>2100</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>121872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Department  WorkedHours  Certification  YearsExperience  Salary\n",
       "0   Development         2300              0              1.1   39343\n",
       "1       Testing         2100              1              1.3   46205\n",
       "2   Development         2104              2              1.5   37731\n",
       "3   UX Designer         1200              1              2.0   43525\n",
       "4       Testing         1254              2              2.2   39891\n",
       "5   UX Designer         1236              1              2.9   56642\n",
       "6   Development         1452              2              3.0   60150\n",
       "7       Testing         1789              1              3.2   54445\n",
       "8   UX Designer         1645              1              3.2   64445\n",
       "9   UX Designer         1258              0              3.7   57189\n",
       "10      Testing         1478              3              3.9   63218\n",
       "11  Development         1257              2              4.0   55794\n",
       "12  Development         1596              1              4.0   56957\n",
       "13      Testing         1256              2              4.1   57081\n",
       "14  UX Designer         1489              3              4.5   61111\n",
       "15  Development         1236              3              4.9   67938\n",
       "16      Testing         2311              2              5.1   66029\n",
       "17  UX Designer         2245              3              5.3   83088\n",
       "18  Development         2365              1              5.9   81363\n",
       "19  Development         1500              3              6.0   93940\n",
       "20      Testing         1456              2              6.8   91738\n",
       "21      Testing         1760              1              7.1   98273\n",
       "22  UX Designer         2400              4              7.9  101302\n",
       "23  Development         2148              3              8.2  113812\n",
       "24  UX Designer         1450              2              8.7  109431\n",
       "25  UX Designer         1000              4              9.0  105582\n",
       "26      Testing         1540              3              9.5  116969\n",
       "27  Development         1500              2              9.6  112635\n",
       "28      Testing         3000              4             10.3  122391\n",
       "29  UX Designer         2100              3             10.5  121872"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After the train/test split section, we perform Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Multiple Linear Regression to Training Set\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "mlrObj= LinearRegression()\n",
    "mlrObj.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Make prediction on the test set\n",
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the Test Set\n",
    "y_pred= mlrObj.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46205  54445  98273  66029 105582  39891]\n",
      "\n",
      "[ 37961.51601741  54861.37364043  91160.08487645  74425.41535057\n",
      " 110256.67948683  44585.24577587]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)\n",
    "print ()\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "- Decide on a significant level for a variable to be retained in the model (usually set at 0.05)\n",
    "- Fit the model with all independent variables.\n",
    "- Select the variable with the highest p-value.\n",
    "- Remove that variable\n",
    "- Fit the model without the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   117.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>4.71e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:31:08</td>     <th>  Log-Likelihood:    </th> <td> -300.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   612.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    24</td>      <th>  BIC:               </th> <td>   620.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.146e+04</td> <td> 4689.376</td> <td>    4.576</td> <td> 0.000</td> <td> 1.18e+04</td> <td> 3.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1421.4255</td> <td> 2683.353</td> <td>   -0.530</td> <td> 0.601</td> <td>-6959.595</td> <td> 4116.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   92.8656</td> <td> 2735.524</td> <td>    0.034</td> <td> 0.973</td> <td>-5552.978</td> <td> 5738.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    3.3361</td> <td>    2.410</td> <td>    1.384</td> <td> 0.179</td> <td>   -1.637</td> <td>    8.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -423.7607</td> <td> 1282.271</td> <td>   -0.330</td> <td> 0.744</td> <td>-3070.237</td> <td> 2222.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 9437.2530</td> <td>  510.978</td> <td>   18.469</td> <td> 0.000</td> <td> 8382.645</td> <td> 1.05e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.020</td> <th>  Durbin-Watson:     </th> <td>   1.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.364</td> <th>  Jarque-Bera (JB):  </th> <td>   1.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.414</td> <th>  Prob(JB):          </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.214</td> <th>  Cond. No.          </th> <td>8.00e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  8e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.952\n",
       "Method:                 Least Squares   F-statistic:                     117.2\n",
       "Date:                Tue, 15 Oct 2019   Prob (F-statistic):           4.71e-16\n",
       "Time:                        20:31:08   Log-Likelihood:                -300.09\n",
       "No. Observations:                  30   AIC:                             612.2\n",
       "Df Residuals:                      24   BIC:                             620.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.146e+04   4689.376      4.576      0.000    1.18e+04    3.11e+04\n",
       "x1         -1421.4255   2683.353     -0.530      0.601   -6959.595    4116.744\n",
       "x2            92.8656   2735.524      0.034      0.973   -5552.978    5738.710\n",
       "x3             3.3361      2.410      1.384      0.179      -1.637       8.310\n",
       "x4          -423.7607   1282.271     -0.330      0.744   -3070.237    2222.716\n",
       "x5          9437.2530    510.978     18.469      0.000    8382.645    1.05e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.020   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.364   Jarque-Bera (JB):                1.629\n",
       "Skew:                           0.414   Prob(JB):                        0.443\n",
       "Kurtosis:                       2.214   Cond. No.                     8.00e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  8e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backward Elimination\n",
    "#import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#We need to add a column of ones to X (corresponding to the intercept term)\n",
    "X = np.append(arr=np.ones((30,1)).astype(int), values=X, axis=1)\n",
    "\n",
    "#According to Backward elimination we first need to fit a model with all variables\n",
    "X_sig= X[:,[0,1,2,3,4,5]]\n",
    "obj_OLS = sm.OLS(endog= y, exog= X_sig).fit()\n",
    "\n",
    "#The summary function displays a table with p-values for all the variables.\n",
    "obj_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   152.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>3.54e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:33:15</td>     <th>  Log-Likelihood:    </th> <td> -300.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   610.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   617.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.151e+04</td> <td> 4315.092</td> <td>    4.986</td> <td> 0.000</td> <td> 1.26e+04</td> <td> 3.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1466.4735</td> <td> 2285.214</td> <td>   -0.642</td> <td> 0.527</td> <td>-6172.961</td> <td> 3240.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.3230</td> <td>    2.331</td> <td>    1.426</td> <td> 0.166</td> <td>   -1.477</td> <td>    8.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -422.1845</td> <td> 1255.570</td> <td>   -0.336</td> <td> 0.739</td> <td>-3008.079</td> <td> 2163.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 9439.2110</td> <td>  497.467</td> <td>   18.975</td> <td> 0.000</td> <td> 8414.659</td> <td> 1.05e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.056</td> <th>  Durbin-Watson:     </th> <td>   1.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.358</td> <th>  Jarque-Bera (JB):  </th> <td>   1.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.407</td> <th>  Prob(JB):          </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.200</td> <th>  Cond. No.          </th> <td>7.20e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.2e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.954\n",
       "Method:                 Least Squares   F-statistic:                     152.6\n",
       "Date:                Tue, 15 Oct 2019   Prob (F-statistic):           3.54e-17\n",
       "Time:                        20:33:15   Log-Likelihood:                -300.09\n",
       "No. Observations:                  30   AIC:                             610.2\n",
       "Df Residuals:                      25   BIC:                             617.2\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.151e+04   4315.092      4.986      0.000    1.26e+04    3.04e+04\n",
       "x1         -1466.4735   2285.214     -0.642      0.527   -6172.961    3240.014\n",
       "x2             3.3230      2.331      1.426      0.166      -1.477       8.124\n",
       "x3          -422.1845   1255.570     -0.336      0.739   -3008.079    2163.710\n",
       "x4          9439.2110    497.467     18.975      0.000    8414.659    1.05e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.056   Durbin-Watson:                   1.918\n",
       "Prob(Omnibus):                  0.358   Jarque-Bera (JB):                1.630\n",
       "Skew:                           0.407   Prob(JB):                        0.443\n",
       "Kurtosis:                       2.200   Cond. No.                     7.20e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.2e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- Select the variable with the highest p-value.\n",
    "#- Remove that variable\n",
    "#- Fit the model without the variable\n",
    "\n",
    "X_sig= X[:,[0,1,3,4,5]]\n",
    "obj_OLS = sm.OLS(endog= y, exog= X_sig).fit()\n",
    "obj_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   210.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>2.35e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:38:10</td>     <th>  Log-Likelihood:    </th> <td> -300.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   608.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   613.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.122e+04</td> <td> 4154.694</td> <td>    5.108</td> <td> 0.000</td> <td> 1.27e+04</td> <td> 2.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1479.8541</td> <td> 2245.558</td> <td>   -0.659</td> <td> 0.516</td> <td>-6095.665</td> <td> 3135.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.3059</td> <td>    2.290</td> <td>    1.443</td> <td> 0.161</td> <td>   -1.402</td> <td>    8.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 9336.1224</td> <td>  385.024</td> <td>   24.248</td> <td> 0.000</td> <td> 8544.694</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.340</td> <th>  Durbin-Watson:     </th> <td>   1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.310</td> <th>  Jarque-Bera (JB):  </th> <td>   1.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.375</td> <th>  Prob(JB):          </th> <td>   0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.124</td> <th>  Cond. No.          </th> <td>7.04e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.04e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.960\n",
       "Model:                            OLS   Adj. R-squared:                  0.956\n",
       "Method:                 Least Squares   F-statistic:                     210.7\n",
       "Date:                Tue, 15 Oct 2019   Prob (F-statistic):           2.35e-18\n",
       "Time:                        20:38:10   Log-Likelihood:                -300.16\n",
       "No. Observations:                  30   AIC:                             608.3\n",
       "Df Residuals:                      26   BIC:                             613.9\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.122e+04   4154.694      5.108      0.000    1.27e+04    2.98e+04\n",
       "x1         -1479.8541   2245.558     -0.659      0.516   -6095.665    3135.956\n",
       "x2             3.3059      2.290      1.443      0.161      -1.402       8.014\n",
       "x3          9336.1224    385.024     24.248      0.000    8544.694    1.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.340   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.310   Jarque-Bera (JB):                1.662\n",
       "Skew:                           0.375   Prob(JB):                        0.436\n",
       "Kurtosis:                       2.124   Cond. No.                     7.04e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.04e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- Select the variable with the highest p-value.\n",
    "#- Remove that variable\n",
    "#- Fit the model without the variable\n",
    "\n",
    "X_sig= X[:,[0,1,3,5]]\n",
    "obj_OLS = sm.OLS(endog= y, exog= X_sig).fit()\n",
    "obj_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   322.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>1.42e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:39:24</td>     <th>  Log-Likelihood:    </th> <td> -300.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   606.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th> <td>   611.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.102e+04</td> <td> 4099.682</td> <td>    5.127</td> <td> 0.000</td> <td> 1.26e+04</td> <td> 2.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.1236</td> <td>    2.250</td> <td>    1.389</td> <td> 0.176</td> <td>   -1.492</td> <td>    7.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 9340.2046</td> <td>  380.920</td> <td>   24.520</td> <td> 0.000</td> <td> 8558.621</td> <td> 1.01e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.451</td> <th>  Durbin-Watson:     </th> <td>   1.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.484</td> <th>  Jarque-Bera (JB):  </th> <td>   1.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.388</td> <th>  Prob(JB):          </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.325</td> <th>  Cond. No.          </th> <td>7.01e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.01e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.960\n",
       "Model:                            OLS   Adj. R-squared:                  0.957\n",
       "Method:                 Least Squares   F-statistic:                     322.5\n",
       "Date:                Tue, 15 Oct 2019   Prob (F-statistic):           1.42e-19\n",
       "Time:                        20:39:24   Log-Likelihood:                -300.41\n",
       "No. Observations:                  30   AIC:                             606.8\n",
       "Df Residuals:                      27   BIC:                             611.0\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.102e+04   4099.682      5.127      0.000    1.26e+04    2.94e+04\n",
       "x1             3.1236      2.250      1.389      0.176      -1.492       7.739\n",
       "x2          9340.2046    380.920     24.520      0.000    8558.621    1.01e+04\n",
       "==============================================================================\n",
       "Omnibus:                        1.451   Durbin-Watson:                   1.842\n",
       "Prob(Omnibus):                  0.484   Jarque-Bera (JB):                1.323\n",
       "Skew:                           0.388   Prob(JB):                        0.516\n",
       "Kurtosis:                       2.325   Cond. No.                     7.01e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.01e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- Select the variable with the highest p-value.\n",
    "#- Remove that variable\n",
    "#- Fit the model without the variable\n",
    "\n",
    "X_sig= X[:,[0,3,5]]\n",
    "obj_OLS = sm.OLS(endog= y, exog= X_sig).fit()\n",
    "obj_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   622.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>1.14e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:40:29</td>     <th>  Log-Likelihood:    </th> <td> -301.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   606.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   609.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.579e+04</td> <td> 2273.053</td> <td>   11.347</td> <td> 0.000</td> <td> 2.11e+04</td> <td> 3.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 9449.9623</td> <td>  378.755</td> <td>   24.950</td> <td> 0.000</td> <td> 8674.119</td> <td> 1.02e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.140</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.343</td> <th>  Jarque-Bera (JB):  </th> <td>   1.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.363</td> <th>  Prob(JB):          </th> <td>   0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.147</td> <th>  Cond. No.          </th> <td>    13.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.957\n",
       "Model:                            OLS   Adj. R-squared:                  0.955\n",
       "Method:                 Least Squares   F-statistic:                     622.5\n",
       "Date:                Tue, 15 Oct 2019   Prob (F-statistic):           1.14e-20\n",
       "Time:                        20:40:29   Log-Likelihood:                -301.44\n",
       "No. Observations:                  30   AIC:                             606.9\n",
       "Df Residuals:                      28   BIC:                             609.7\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.579e+04   2273.053     11.347      0.000    2.11e+04    3.04e+04\n",
       "x1          9449.9623    378.755     24.950      0.000    8674.119    1.02e+04\n",
       "==============================================================================\n",
       "Omnibus:                        2.140   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.343   Jarque-Bera (JB):                1.569\n",
       "Skew:                           0.363   Prob(JB):                        0.456\n",
       "Kurtosis:                       2.147   Cond. No.                         13.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- Select the variable with the highest p-value.\n",
    "#- Remove that variable\n",
    "#- Fit the model without the variable\n",
    "\n",
    "X_sig= X[:,[0,5]]\n",
    "obj_OLS = sm.OLS(endog= y, exog= X_sig).fit()\n",
    "obj_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backward Elimination is now complete. Let us now build a model using the significant predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Training Set and Test Set\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test= train_test_split(X_sig, y, test_size=0.2,random_state=0)\n",
    "\n",
    "mlrObj_sig= LinearRegression()\n",
    "mlrObj_sig.fit(X_sig_train, y_sig_train)\n",
    "\n",
    "y_sig_pred= mlrObj_sig.predict(X_sig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46205  54445  98273  66029 105582  39891]\n",
      "\n",
      "[ 37961.51601741  54861.37364043  91160.08487645  74425.41535057\n",
      " 110256.67948683  44585.24577587]\n",
      "\n",
      "[ 40748.96184072 122699.62295594  64961.65717022  63099.14214487\n",
      " 115249.56285456 107799.50275317]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)\n",
    "print ()\n",
    "print (y_pred)\n",
    "print ()\n",
    "print (y_sig_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'income' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-70411a2c48c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mFP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mTN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'income' is not defined"
     ]
    }
   ],
   "source": [
    "TP = np.sum(income) \n",
    "FP = income.count() - TP \n",
    "TN = 0 \n",
    "FN = 0\n",
    "\n",
    "# TODO: Calculate accuracy, precision and recall [True Positives/(True Positives + False Negatives)]\n",
    "accuracy = float (TP) / (TP+FP)\n",
    "recall = float (TP) / (TP+FN)\n",
    "precision = float (TP) / (TP+FP)\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall. \n",
    "# 𝐹𝛽 =(1+𝛽2) * (𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 * 𝑟𝑒𝑐𝑎𝑙𝑙) / ((𝛽2*𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛) + 𝑟𝑒𝑐𝑎𝑙𝑙)\n",
    "b2 = 0.5 #Beta = 0.5\n",
    "fscore = (1+ b2**2)*(precision*recall)/((b2**2 * precision)+ recall)\n",
    "\n",
    "# Print the results \n",
    "print(\"MLR: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
